{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TC_GradCAM.ipynb","provenance":[],"collapsed_sections":["ZlzbEFHyZWmy"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/raquelcarmo/tropical_cyclones/blob/import-py-files/src/code/TC_GradCAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"D-_u8sEYbzAF"},"source":["##Imports and configurations"]},{"cell_type":"code","metadata":{"id":"dj7JZ5lPCZvm"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AyL3l3Z1TBHj"},"source":["%cd /content/drive/My Drive/ESRIN_PhiLab/Tropical_Cyclones/tropical_cyclones/src/code\n","%ls\n","\n","import imp \n","# import helper.py\n","helper = imp.new_module('helper_functions')\n","exec(open(\"./helper_functions.py\").read(), helper.__dict__)\n","# import models.py\n","models = imp.new_module('models')\n","exec(open(\"./models.py\").read(), models.__dict__)\n","# import data_processor.py\n","dp = imp.new_module('data_processor')\n","exec(open(\"./data_processor.py\").read(), dp.__dict__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3d95OmlLCDSj"},"source":["# getting in the directory \n","%cd /content/drive/My Drive/ESRIN_PhiLab/Tropical_Cyclones/data\n","%ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8tbWAaHayf0"},"source":["# general imports\n","import random\n","import glob\n","import os\n","import sys\n","sys.stdout.flush()\n","import pandas as pd\n","import numpy as np\n","from keras import backend as K\n","import cv2\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import math\n","import imageio\n","import os.path\n","from PIL import Image\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","from scipy import ndimage\n","from google.colab.patches import cv2_imshow\n","import random\n","from shapely.geometry import Point\n","import re\n","import pickle\n","import scipy\n","from sklearn.model_selection import StratifiedKFold\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n","import datetime\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.data import Dataset\n","from tensorflow.keras import Input\n","from tensorflow.keras.applications import resnet50, mobilenet_v2\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import concatenate, Dense, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import SGD, Adam\n","from tensorflow.keras.metrics import CategoricalAccuracy, Precision, Recall, TruePositives, FalsePositives, TrueNegatives, FalseNegatives\n","\n","np.set_printoptions(precision=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mNuQlrZaKCjK"},"source":["def get_img_array(img_path, size):\n","    # `img` is a PIL image of size 299x299\n","    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n","    # `array` is a float32 Numpy array of shape (299, 299, 3)\n","    array = keras.preprocessing.image.img_to_array(img)\n","    # We add a dimension to transform our array into a \"batch\" of size (1, 299, 299, 3)\n","    array = np.expand_dims(array, axis=0)\n","    return array\n","\n","\n","def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n","    # First, we create a model that maps the input image to the activations of the last conv layer\n","    last_conv_layer = model.get_layer(last_conv_layer_name)\n","    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n","\n","    # Second, we create a model that maps the activations of the last conv layer to the final class predictions\n","    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n","    x = classifier_input\n","    for layer_name in classifier_layer_names:\n","        x = model.get_layer(layer_name)(x)\n","    classifier_model = keras.Model(classifier_input, x)\n","\n","    # Then, we compute the gradient of the top predicted class for our input image\n","    # with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        # Compute activations of the last conv layer and make the tape watch it\n","        last_conv_layer_output = last_conv_layer_model(img_array)\n","        tape.watch(last_conv_layer_output)\n","        # Compute class predictions\n","        preds = classifier_model(last_conv_layer_output)\n","        top_pred_index = tf.argmax(preds[0])\n","        top_class_channel = preds[:, top_pred_index]\n","\n","    # This is the gradient of the top predicted class with regard to\n","    # the output feature map of the last conv layer\n","    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient\n","    # over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array\n","    # by \"how important this channel is\" with regard to the top predicted class\n","    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n","    pooled_grads = pooled_grads.numpy()\n","    for i in range(pooled_grads.shape[-1]):\n","        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n","\n","    # The channel-wise mean of the resulting feature map is our heatmap of class activation\n","    heatmap = np.mean(last_conv_layer_output, axis=-1)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n","    return heatmap"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u98-zRy8uPst"},"source":["Load previously saved model."]},{"cell_type":"code","metadata":{"id":"ES-VLu14RD2d"},"source":["main_dir = \"SAR_swath_images_VV+VH+WS/\"\n","dir = main_dir + \"classification_results/categorization/ResNet_Numeric-F_BatchSize-8_lr-0.0001_Epochs-20_Folds-5_Norm-T_Aug-T/\"\n","#dir = main_dir + \"classification_results/identification/ResNet_Numeric-F_BatchSize-8_lr-0.0001_Epochs-20_Folds-5_Norm-T/\"\n","#save_path = dir + \"Gradcam_heatmaps\"\n","#os.makedirs(save_path, exist_ok=True)\n","\n","# load previously saved model\n","model = tf.keras.models.load_model(dir + \"model_4.h5\", compile = False)\n","#model = tf.keras.models.load_model(dir + \"best_model_fine_tuned_4.h5\", compile = False)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mj3Bq4NqYEKz"},"source":["# source: https://stackoverflow.com/questions/50283844/in-keras-how-to-get-the-layer-name-associated-with-a-model-object-contained-i\n","last_conv_layer_name = model.get_layer('resnet50').layers[-1].name\n","last_conv_layer = model.get_layer('resnet50').get_layer(last_conv_layer_name)\n","\n","print(\"last_conv_layer_name:\", last_conv_layer_name)\n","print(\"last_conv_layer:\", last_conv_layer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwSqTJxwfm2B"},"source":["last_conv_layer.output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jV85inIWe025"},"source":["model.get_layer('resnet50').summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QrOlIQwhhBJ"},"source":["model.inputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjFVVeIokkl2"},"source":["model.get_layer(\"resnet50\").inputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"enp8jEjVcskL"},"source":["from tensorflow import keras\n","last_conv_layer_model = keras.Model(model.get_layer(\"resnet50\").inputs, last_conv_layer.output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"roojlKM5iIoh"},"source":["classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n","x = classifier_input\n","classifier_layer_names = [\n","    \"global_average_pooling2d\",\n","    \"dense\"]\n","for layer_name in classifier_layer_names:\n","    x = model.get_layer(layer_name)(x)\n","classifier_model = keras.Model(classifier_input, x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aVNn9rqcL47a"},"source":["model.get_layer('mobilenetv2_1.00_224').layers[-1].name\n","[layer.name for layer in model.layers[-2:]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C6gNBlB1Gsdf"},"source":["last_conv_layer_name = \"conv5_block3_out\"\n","\n","# check the names with model.summary(), sometimes recreating the model multiple times for testing the names can change\n","classifier_layer_names = [\n","    \"global_average_pooling2d\",\n","    \"dense\"\n","    #\"global_average_pooling2d_1\",\n","    #\"dense_1\"\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkJlSAA1G0ri"},"source":["Actual GradCam testing"]},{"cell_type":"code","metadata":{"id":"HbDZQa2jDwZg"},"source":["\"\"\"\n","MIN_HEIGHT = 700\n","MIN_WIDTH = 400\n","BATCH_SIZE = 1\n","NETWORK = \"ResNet\"\n","\n","# Preprocess image\n","df = pd.read_csv(main_dir + \"/csv/full_dataset.csv\", converters={'bbox_shape': eval}).dropna()\n","images, labels, bboxes = helper.load_from_df(df)\n","\n","# create an instance of the DataProcessor\n","processor = DataProcessor(model = NETWORK,\n","                          min_height = MIN_HEIGHT,\n","                          min_width = MIN_WIDTH)\n","\n","processed_image = np.array([processor.preprocess_pipeline(images[2], bboxes[2])])\n","\n","# Print what the top predicted class is\n","preds = model.predict(processed_image)\n","#print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n","print(preds)\n","print(labels[2])\n","# Generate class activation heatmap\n","heatmap = make_gradcam_heatmap(\n","    processed_image, model, last_conv_layer_name, classifier_layer_names\n",")\n","\n","# Display heatmap\n","plt.matshow(heatmap)\n","plt.show()\n","sys.exit(\"Stop\")\n","############################################\n","###  SUPERIMPOSED GARDCAM VISUALIZATION  ###\n","############################################\n","\n","# Load the original image\n","img = keras.preprocessing.image.load_img(images[0])\n","img = keras.preprocessing.image.img_to_array(img)\n","\n","# Rescale heatmap to a range 0-255\n","heatmap = np.uint8(255 * heatmap)\n","\n","# Use jet colormap to colorize heatmap\n","jet = cm.get_cmap(\"jet\")\n","\n","# Use RGB values of the colormap\n","jet_colors = jet(np.arange(256))[:, :3]\n","jet_heatmap = jet_colors[heatmap]\n","\n","# Create an image with RGB colorized heatmap\n","jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n","jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n","\n","# Superimpose the heatmap on original image\n","superimposed_img = jet_heatmap * 0.4 + img\n","superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n","\n","# Save the superimposed image\n","#superimposed_img.save(save_path)\n","\n","# Display Grad CAM\n","display(Image(save_path))\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFJsZMlNKDah"},"source":["# ATTENTION: to use this code, make sure that processor has:\n","#    #image_path = image_path.numpy().decode('utf-8')\n","#    #bbox = bbox.numpy()\n","#    image = cv2.imread(image_path)#.astype(np.float32) # loads images as BGR in float32\n","#    #image = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)   # BGR -> RGB\n","#    return sized_image, output_image \n","\n","MIN_HEIGHT = 700\n","MIN_WIDTH = 400\n","BATCH_SIZE = 1\n","NETWORK = \"ResNet\"\n","categorization = True\n","\n","# Preprocess image\n","csv_path = main_dir + \"/csv/full_dataset.csv\"\n","images, labels, bboxes = helper.load_data(csv_path, with_cat = categorization)\n","\n","# create an instance of the DataProcessor\n","processor = dp.DataProcessor(model = NETWORK,\n","                          min_height = MIN_HEIGHT,\n","                          min_width = MIN_WIDTH,\n","                          normalise = True)\n","\n","count = -1\n","for image, bbox, label in zip(images, bboxes, labels):\n","    count += 1\n","\n","    if count == 204:\n","        orig_image, processed_image = processor.preprocess_pipeline(image, bbox)\n","        #orig_image = np.transpose(orig_image,(1,0,2))\n","        orig_image = tf.transpose(orig_image, [1,0,2])\n","\n","        processed_image = tf.transpose(processed_image, [1,0,2])\n","        processed_image = tf.expand_dims(processed_image, axis=0)\n","        #processed_image = np.array([processed_image])\n","        #processed_image = np.expand_dims(processed_image, axis=0)\n","\n","        # Print what the top predicted class is\n","        preds = model.predict(processed_image)\n","        #print(\"Predicted:\", decode_predictions(preds, top=1)[0])\n","        predictions = np.round(preds[0],2) if categorization else preds[0]\n","        print(\"Prediction: {}, True label: {}\".format(predictions, label))\n","\n","        # Generate class activation heatmap\n","        heatmap = make_gradcam_heatmap(processed_image, model, last_conv_layer_name, classifier_layer_names)\n","\n","        # Display heatmap\n","        #plt.matshow(heatmap)\n","        #plt.show()\n","        #plt.imshow(orig_image[:,:,1])\n","        #plt.show()\n","        #plt.imshow(orig_image[:,:,2])\n","        #plt.show()\n","\n","        ############################################\n","        ###  SUPERIMPOSED GARDCAM VISUALIZATION  ###\n","        ############################################\n","        # Load the original image\n","        #plt.imshow(orig_image)\n","        #plt.title(\"Original Image\")\n","        #plt.show()\n","        #img = keras.preprocessing.image.load_img(image)\n","        #img = keras.preprocessing.image.img_to_array(img)\n","\n","        # Rescale heatmap to a range 0-255\n","        heatmap = np.uint8(255 * heatmap)\n","\n","        # Use jet colormap to colorize heatmap\n","        jet = cm.get_cmap(\"jet\")\n","\n","        # Use RGB values of the colormap\n","        jet_colors = jet(np.arange(256))[:, :3]\n","        jet_heatmap = jet_colors[heatmap]\n","\n","        # Create an image with RGB colorized heatmap\n","        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n","        jet_heatmap = jet_heatmap.resize((orig_image.shape[1], orig_image.shape[0]))\n","        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n","        jet_heatmap_img = keras.preprocessing.image.array_to_img(jet_heatmap)\n","\n","        # Superimpose the heatmap on original image\n","        vv_channel = np.dstack((orig_image[:,:,2], orig_image[:,:,2], orig_image[:,:,2]))\n","        vh_channel = np.dstack((orig_image[:,:,1], orig_image[:,:,1], orig_image[:,:,1]))\n","        superimposed_img = jet_heatmap * 0.4 + vv_channel\n","        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n","\n","        # Save the superimposed image\n","        #superimposed_img.save(save_path)\n","\n","        # Display Grad CAM\n","        #display(Image(save_path))\n","        #plt.imshow(superimposed_img)\n","        #plt.title(\"Superimposed Image\")\n","        #plt.show()\n","\n","        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize = (15,9.2))\n","        font_size = 18\n","        ax1.imshow(vv_channel)    # plot vv channel\n","        ax1.set_title(\"Original Image (VV) - label: {}\".format(label), fontsize = font_size)\n","\n","        #ax2.imshow(np.squeeze(processed_image, axis=0))\n","        #ax2.set(title = \"Normalised Image\")\n","        ax2.imshow(vh_channel)  # plot vh channel\n","        ax2.set_title(\"Original Image (VH)\", fontsize = font_size)\n","\n","        #ax3.matshow(heatmap)\n","        #ax3.set(title = \"Heatmap - prediction: {}\".format(predictions))\n","        heat_plot = ax3.imshow(jet_heatmap_img, cmap='jet')\n","        ax3.set_title(\"Heatmap - prediction: {}\".format(predictions), fontsize = font_size)\n","        divider = make_axes_locatable(ax3)\n","        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n","        plt.colorbar(heat_plot, cax=cax)\n","\n","        ax4.imshow(superimposed_img)\n","        ax4.set_title(\"Superimposed Image\", fontsize = font_size)\n","        fig.tight_layout()\n","        plt.show()\n","        \n","        #fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize = (15,12))\n","        #ax1.imshow(vv_channel)  # plot vv channel\n","        #ax1.set(title = \"Original Image (VV) - label: {}\".format(label))\n","\n","        #ax2.imshow(vh_channel)  # plot vh channel\n","        #ax2.set(title = \"Original Image (VH)\")\n","\n","        #heat_plot = ax3.imshow(jet_heatmap, cmap='jet')\n","        #ax3.set(title = \"Heatmap - prediction: {}\".format(predictions))\n","        #divider = make_axes_locatable(ax3)\n","        #cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n","        #plt.colorbar(heat_plot, cax=cax)\n","\n","        #ax4.imshow(superimposed_img)\n","        #ax4.set(title = \"Superimposed Image\")\n","        #fig.tight_layout()\n","        #plt.show()\n","\n","        #fig.savefig(\"{}/id_resnet_gradcam.jpg\".format(save_path))\n","        #fig.savefig(\"{}/superimposed_{}.jpg\".format(save_path, count))\n","        fig.savefig(\"{}/superimposed_{}.jpg\".format(dir, np.random.randint(low=1, high=100, size=1)[0]), box_layout='tight')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kq36IoxN0JO4"},"source":["save_path = dir + \"gradcam_heatmaps_{}\".format(fold_var)\n","os.makedirs(save_path, exist_ok=True)\n","\n","def grad_cam(model, NETWORK, val_dataset, val_norm_dataset, save_path):\n","    cnt = 0\n","    if NETWORK == \"ResNet\":\n","        # check the names with model.summary()\n","        last_conv_layer_name = \"conv5_block3_out\"\n","        \n","        classifier_layer_names = [\n","            \"global_average_pooling2d\",\n","            \"dense\"\n","            ]\n","            \n","    else:  #MobileNetV2\n","        last_conv_layer_name = \"out_relu\" # have to check this again\n","        \n","        classifier_layer_names = [\n","            \"global_average_pooling2d_1\",\n","            \"dense_1\"\n","            ]\n","\n","    for orig_image, label, processed_image, processed_label in zip(val_dataset, val_norm_dataset):\n","        # label and norm_label should be the same\n","\n","        pred = model.predict(processed_image)\n","        prediction = np.round(pred[0],2) #if categorization else pred[0]\n","\n","        heatmap = make_gradcam_heatmap(\n","            processed_image, model, last_conv_layer_name, classifier_layer_names\n","            )\n","\n","        # Rescale heatmap to a range 0-255\n","        heatmap = np.uint8(255 * heatmap)\n","\n","        # Use jet colormap to colorize heatmap\n","        jet = cm.get_cmap(\"jet\")\n","\n","        # Use RGB values of the colormap\n","        jet_colors = jet(np.arange(256))[:, :3]\n","        jet_heatmap = jet_colors[heatmap]\n","\n","        # Create an image with RGB colorized heatmap\n","        jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n","        jet_heatmap = jet_heatmap.resize((orig_image.shape[1], orig_image.shape[0]))\n","        jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n","\n","        # Superimpose the heatmap on original image\n","        vv_channel = np.dstack((orig_image[:,:,0], orig_image[:,:,0], orig_image[:,:,0]))\n","        vh_channel = np.dstack((orig_image[:,:,1], orig_image[:,:,1], orig_image[:,:,1]))\n","        superimposed_img = jet_heatmap * 0.4 + vv_channel\n","        superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n","\n","        # Display Grad CAM\n","        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize = (15,9.2))\n","        font_size = 18\n","        ax1.imshow(vv_channel)    # plot vv channel\n","        ax1.set_title(\"Original Image (VV) - label: {}\".format(label), fontsize = font_size)\n","        ax2.imshow(vh_channel)  # plot vh channel\n","        ax2.set_title(\"Original Image (VH)\", fontsize = font_size)\n","        heat_plot = ax3.imshow(jet_heatmap, cmap='jet')\n","        ax3.set_title(\"Heatmap - prediction: {}\".format(prediction), fontsize = font_size)\n","        divider = make_axes_locatable(ax3)\n","        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n","        plt.colorbar(heat_plot, cax=cax)\n","        ax4.imshow(superimposed_img)\n","        ax4.set_title(\"Superimposed Image\", fontsize = font_size)\n","        fig.tight_layout()\n","        #plt.show()\n","\n","        fig.savefig(\"{}/heatmap_{}.jpg\".format(save_path, cnt), bbox_inches='tight')\n","        cnt += 1\n","\n","    return"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_r55veE3mzbP"},"source":["##################################\n","###          SETTINGS         ####\n","##################################\n","main_dir = \"SAR_swath_images_VV+VH+WS_dilated\"\n","NETWORK = \"ResNet\"     # options: [\"Mobile\", \"ResNet\", \"VGG\"]\n","MIN_HEIGHT = MIN_WIDTH = 384\n","EYE_ONLY = True\n","NUM_VARS = False\n","NORMALISE = True\n","NORM_MODE = \"model\" # options: [\"model\", \"z-norm\", \"simple\", \"none\"]\n","ROTATE = False\n","N_CROPS = 1\n","CROP_MODE = \"uniform\" # options: [\"uniform\", \"weighted\"]\n","AUGMENT = True\n","BATCH_SIZE = 8\n","BUFFER_SIZE = 100\n","SPLIT_NUMBER = 5\n","##################################\n","\n","full_dataset_path = \"{}/csv/full_dataset.csv\".format(main_dir)\n","df = pd.read_csv(full_dataset_path, converters={'bbox_shape': eval}).dropna()\n","print(\"Dataset dimension: {}\".format(len(df)))\n","\n","\n","# extract non-categorical labels for StratifiedKFold\n","Y = np.zeros(len(df), dtype=int)\n","for index, row in df.iterrows():\n","    if df[\"label\"][index] != 0:\n","        cat = df[\"image\"][index].split('/')[1]\n","        Y[index] = int(cat[-1])\n","\n","if EYE_ONLY:\n","    assert isinstance(Y, np.ndarray)\n","    idx = np.where(Y == 0)[0].tolist()\n","    Y = np.delete(Y, idx)\n","    Y -= 1\n","    df.drop(idx, inplace = True)\n","    df.reset_index(drop=True, inplace=True)\n","    print(\"New dimensions, Y: {} and df: {}\".format(len(Y), len(df)))\n","\n","\n","# create an instance of the DataProcessor\n","processor = dp.DataProcessor(model = NETWORK,\n","                            min_height = MIN_HEIGHT,\n","                            min_width = MIN_WIDTH,\n","                            normalise = NORMALISE,           # perform normalisation [DEPRECATED]\n","                            rotate = ROTATE,                 # perform rotation\n","                            plot_light = False,              # plot only select_crop() images\n","                            plot_extensive = False,          # plot extensively all images\n","                            show_prints = False)\n","\n","\n","print(\"Entering in k fold cross validation...\")\n","stratified_k_fold = StratifiedKFold(n_splits = SPLIT_NUMBER, shuffle = False)\n","fold_var = 1\n","\n","for train_index, val_index in stratified_k_fold.split(np.zeros(len(df)), Y):\n","    training_data = df.iloc[train_index]\n","    validation_data = df.iloc[val_index]\n","\n","    # LOAD DATA\n","    train_images, train_labels, train_bbox = helper.load_data(df = training_data, eye_only = EYE_ONLY)\n","    val_images, val_labels, val_bbox = helper.load_data(df = validation_data, eye_only = EYE_ONLY)\n","\n","    # GENERATE DATASETS\n","    train_dataset = helper.create_dataset(processor, train_images, train_labels, train_bbox, N_CROPS, CROP_MODE, MIN_HEIGHT, MIN_WIDTH)\n","    val_dataset = helper.create_dataset(processor, val_images, val_labels, val_bbox, 1, CROP_MODE, MIN_HEIGHT, MIN_WIDTH)\n","\n","    # PERFORM NORMALISATION\n","    if NORMALISE:\n","        train_norm_dataset, val_norm_dataset = helper.normalisation(train_dataset, val_dataset, mode = NORM_MODE, model = NETWORK)\n","    else:\n","        train_norm_dataset = train_dataset\n","        val_norm_dataset = val_dataset\n","    unbatched_train_norm_dataset, unbatched_val_norm_dataset = train_norm_dataset, val_norm_dataset\n","\n","    # CONFIGURE FOR PERFORMANCE\n","    #SQUARED = True if MIN_HEIGHT == MIN_WIDTH else False\n","    #train_norm_dataset = helper.configure_for_performance(train_norm_dataset, BUFFER_SIZE, BATCH_SIZE, shuffle = True, augment = AUGMENT, squared_input = SQUARED)\n","    val_norm_dataset = helper.configure_for_performance(val_norm_dataset, BUFFER_SIZE, BATCH_SIZE)\n","\n","    # load previously saved model\n","    main_dir = \"SAR_swath_images_VV+VH+WS_dilated/\"\n","    dir = main_dir + \"classification_results/categorization/test_eye_only/ResNet_nu-F_bs-8_384x384_lr-1e-05_ep-30_sp-5_no-mT_cr-u1_ag-T_drp-F/\"\n","    model = tf.keras.models.load_model(dir + \"model_2.h5\", compile = False)\n","\n","    # GRAD-CAM ANALYSIS\n","    predictions = model.predict(val_norm_dataset)\n","    helper.grad_cam(model, val_dataset, unbatched_val_norm_dataset, predictions, save_path = \"\")\n","\n","    fold_var +=1\n","    if fold_var == 2:\n","        sys.exit()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZlzbEFHyZWmy"},"source":["##2. Test other grad-cam code\n","\n","Source: https://github.com/eclique/keras-gradcam/blob/master/grad_cam.py"]},{"cell_type":"code","metadata":{"id":"X6yFyaA5ZRDA"},"source":["def grad_cam(input_model, image, cls, layer_name):\n","    \"\"\"GradCAM method for visualizing input saliency.\"\"\"\n","    y_c = input_model.output[0, cls.numpy()]\n","    conv_output = input_model.get_layer(layer_name).output\n","    grads = K.gradients(y_c, conv_output)[0]\n","    # Normalize if necessary\n","    # grads = normalize(grads)\n","    gradient_function = K.function([input_model.input], [conv_output, grads])\n","\n","    output, grads_val = gradient_function([image])\n","    output, grads_val = output[0, :], grads_val[0, :, :, :]\n","\n","    weights = np.mean(grads_val, axis=(0, 1))\n","    cam = np.dot(output, weights)\n","\n","    # Process CAM\n","    cam = cv2.resize(cam, (W, H), cv2.INTER_LINEAR)\n","    cam = np.maximum(cam, 0)\n","    cam_max = cam.max() \n","    if cam_max != 0: \n","        cam = cam / cam_max\n","    return cam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oRPvybGfZVwm"},"source":["def compute_saliency(model, val_dataset, val_norm_dataset, predictions, layer_name='block5_conv3', cls=-1, visualize=True, save=False):\n","    \"\"\"Compute saliency using all three approaches.\n","        -layer_name: layer to compute gradients;\n","        -cls: class number to localize (-1 for most probable class).\n","    \"\"\"\n","\n","    val_norm_images = val_norm_dataset.map(lambda x, y: x)\n","    val_norm_labels = val_norm_dataset.map(lambda x, y: y)\n","    val_images = val_dataset.map(lambda x, y: x)\n","    val_labels = val_dataset.map(lambda x, y: y)\n","\n","    for orig_image, label, processed_image, processed_label, prediction in zip(val_images, val_labels, val_norm_images, val_norm_labels, predictions):\n","        # label and norm_label should be the same\n","\n","        #predictions = model.predict(processed_image)\n","\n","        #predictions = model.predict(preprocessed_input)\n","        #top_n = 5\n","        #top = decode_predictions(predictions, top=top_n)[0]\n","        #classes = np.argsort(predictions[0])[-top_n:][::-1]\n","        #print('Model prediction:')\n","        #for c, p in zip(classes, top):\n","        #    print('\\t{:15s}\\t({})\\twith probability {:.3f}'.format(p[1], c, p[2]))\n","        #if cls == -1:\n","        #    cls = np.argmax(predictions)\n","        #class_name = decode_predictions(np.eye(1, 1000, cls))[0][0][1]\n","        #print(\"Explanation for '{}'\".format(class_name))\n","        \n","        gradcam = grad_cam(model, processed_image, label, layer_name)\n","        #gb = guided_backprop(guided_model, preprocessed_input, layer_name)\n","        #guided_gradcam = gb * gradcam[..., np.newaxis]\n","\n","        if save:\n","            jetcam = cv2.applyColorMap(np.uint8(255 * gradcam), cv2.COLORMAP_JET)\n","            jetcam = (np.float32(jetcam) + load_image(img_path, preprocess=False)) / 2\n","            cv2.imwrite('gradcam.jpg', np.uint8(jetcam))\n","            cv2.imwrite('guided_backprop.jpg', deprocess_image(gb[0]))\n","            cv2.imwrite('guided_gradcam.jpg', deprocess_image(guided_gradcam[0]))\n","        \n","        if visualize:\n","            plt.figure(figsize=(15, 10))\n","            #plt.subplot(131)\n","            plt.title('GradCAM')\n","            plt.axis('off')\n","            plt.imshow(load_image(img_path, preprocess=False))\n","            plt.imshow(gradcam, cmap='jet', alpha=0.5)\n","\n","            #plt.subplot(132)\n","            #plt.title('Guided Backprop')\n","            #plt.axis('off')\n","            #plt.imshow(np.flip(deprocess_image(gb[0]), -1))\n","            \n","            #plt.subplot(133)\n","            #plt.title('Guided GradCAM')\n","            #plt.axis('off')\n","            #plt.imshow(np.flip(deprocess_image(guided_gradcam[0]), -1))\n","            #plt.show()\n","            \n","        return gradcam#, gb, guided_gradcam"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9yOZf0fcYdV"},"source":["##################################\n","###          SETTINGS         ####\n","##################################\n","main_dir = \"SAR_swath_images_VV+VH+WS_dilated\"\n","NETWORK = \"ResNet\"     # options: [\"Mobile\", \"ResNet\", \"VGG\"]\n","MIN_HEIGHT = MIN_WIDTH = 384\n","EYE_ONLY = True\n","NUM_VARS = False\n","NORMALISE = True\n","NORM_MODE = \"model\" # options: [\"model\", \"z-norm\", \"simple\", \"none\"]\n","ROTATE = False\n","N_CROPS = 1\n","CROP_MODE = \"uniform\" # options: [\"uniform\", \"weighted\"]\n","AUGMENT = True\n","BATCH_SIZE = 8\n","BUFFER_SIZE = 100\n","SPLIT_NUMBER = 5\n","##################################\n","\n","full_dataset_path = \"{}/csv/full_dataset.csv\".format(main_dir)\n","df = pd.read_csv(full_dataset_path, converters={'bbox_shape': eval}).dropna()\n","print(\"Dataset dimension: {}\".format(len(df)))\n","\n","\n","# extract non-categorical labels for StratifiedKFold\n","Y = np.zeros(len(df), dtype=int)\n","for index, row in df.iterrows():\n","    if df[\"label\"][index] != 0:\n","        cat = df[\"image\"][index].split('/')[1]\n","        Y[index] = int(cat[-1])\n","\n","if EYE_ONLY:\n","    assert isinstance(Y, np.ndarray)\n","    idx = np.where(Y == 0)[0].tolist()\n","    Y = np.delete(Y, idx)\n","    Y -= 1\n","    df.drop(idx, inplace = True)\n","    df.reset_index(drop=True, inplace=True)\n","    print(\"New dimensions, Y: {} and df: {}\".format(len(Y), len(df)))\n","\n","\n","# create an instance of the DataProcessor\n","processor = dp.DataProcessor(model = NETWORK,\n","                            min_height = MIN_HEIGHT,\n","                            min_width = MIN_WIDTH,\n","                            normalise = NORMALISE,           # perform normalisation [DEPRECATED]\n","                            rotate = ROTATE,                 # perform rotation\n","                            plot_light = False,              # plot only select_crop() images\n","                            plot_extensive = False,          # plot extensively all images\n","                            show_prints = False)\n","\n","\n","print(\"Entering in k fold cross validation...\")\n","stratified_k_fold = StratifiedKFold(n_splits = SPLIT_NUMBER, shuffle = False)\n","fold_var = 1\n","\n","for train_index, val_index in stratified_k_fold.split(np.zeros(len(df)), Y):\n","    training_data = df.iloc[train_index]\n","    validation_data = df.iloc[val_index]\n","\n","    # LOAD DATA\n","    train_images, train_labels, train_bbox = helper.load_data(df = training_data, eye_only = EYE_ONLY)\n","    val_images, val_labels, val_bbox = helper.load_data(df = validation_data, eye_only = EYE_ONLY)\n","\n","    # GENERATE DATASETS\n","    train_dataset = helper.create_dataset(processor, train_images, train_labels, train_bbox, N_CROPS, CROP_MODE, MIN_HEIGHT, MIN_WIDTH)\n","    val_dataset = helper.create_dataset(processor, val_images, val_labels, val_bbox, 1, CROP_MODE, MIN_HEIGHT, MIN_WIDTH)\n","\n","    # PERFORM NORMALISATION\n","    if NORMALISE:\n","        train_norm_dataset, val_norm_dataset = helper.normalisation(train_dataset, val_dataset, mode = NORM_MODE, model = NETWORK)\n","    else:\n","        train_norm_dataset = train_dataset\n","        val_norm_dataset = val_dataset\n","    unbatched_train_norm_dataset, unbatched_val_norm_dataset = train_norm_dataset, val_norm_dataset\n","\n","    # CONFIGURE FOR PERFORMANCE\n","    #SQUARED = True if MIN_HEIGHT == MIN_WIDTH else False\n","    #train_norm_dataset = helper.configure_for_performance(train_norm_dataset, BUFFER_SIZE, BATCH_SIZE, shuffle = True, augment = AUGMENT, squared_input = SQUARED)\n","    val_norm_dataset = helper.configure_for_performance(val_norm_dataset, BUFFER_SIZE, BATCH_SIZE)\n","\n","    # load previously saved model\n","    main_dir = \"SAR_swath_images_VV+VH+WS_dilated/\"\n","    dir = main_dir + \"classification_results/categorization/test_eye_only/ResNet_nu-F_bs-8_384x384_lr-1e-05_ep-30_sp-5_no-mT_cr-u1_ag-T_drp-F/\"\n","    model = tf.keras.models.load_model(dir + \"model_2.h5\", compile = False)\n","\n","    # GRAD-CAM ANALYSIS\n","    predictions = model.predict(val_norm_dataset)\n","    compute_saliency(model, val_dataset, unbatched_val_norm_dataset, predictions, layer_name='block5_conv3', cls=-1, visualize=True, save=False)\n","\n","    fold_var +=1\n","    if fold_var == 2:\n","        sys.exit()"],"execution_count":null,"outputs":[]}]}